{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<03 Markdown to manifest 1.jpg>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Let's begin by installing and importing all of the different components we will need.\n",
    "\n",
    "- proposer un mod√®le de markdown ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and importing packages...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üëç Ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing and importing packages...\")\n",
    "\n",
    "# Uninstall and reinstall packages for a clean environment\n",
    "%pip uninstall -q -y arvestapi\n",
    "%pip install -q --disable-pip-version-check git+https://github.com/arvest-data-in-context/arvest-api.git\n",
    "%pip install -q iiif_prezi3\n",
    "\n",
    "\n",
    "# !pip uninstall -q -y jhutils\n",
    "# !pip install -q --disable-pip-version-check git+https://github.com/jdchart/jh-py-utils.git\n",
    "\n",
    "# !pip uninstall -q -y arvesttools\n",
    "# !pip install -q --disable-pip-version-check git+https://github.com/arvest-data-in-context/arvest-api-tools.git\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "from arvesttools.md_to_manifest import md_to_manifest, metadata_update\n",
    "\n",
    "print(\"üëç Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare your files\n",
    " \n",
    "First we need to your Arvest user email and password and the path of the folder were you have stock your markdown files and of the folder where you want to load your manifest files before upload there to Arverst\n",
    "For each markdown files in the markdown folder, this script will create a separate json file and upload it on Arvest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Arvest user email and password\n",
    "\n",
    "ARVEST_MAIL = \"aryodeliae@gmail.com\"\n",
    "ARVEST_PASSWORD = \"Arvestmoon1203\"\n",
    "\n",
    "# The folder's path were you want to load your manifest\n",
    "\n",
    "MARKDOWN_PATH = os.path.join(os.getcwd(),\"Boite a md\")\n",
    "MANIFEST_PATH = os.path.join(os.getcwd(),\"Boite a manifest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Launch the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening statements\n",
      "Keynote - Scott deLaHunta ¬¨ Software for Dancers\n",
      "Olivier Aubert ¬¨ Advene', ' a Look Back on 20 Years of Video Annotation Instrumentation\n",
      "Mark J. Williams ¬¨ Deep Screens and Evocative Surfaces\n",
      "Michael Rau & Peter Broadwell ¬¨ Machine Intelligence for Motion Exegesis (MIME)\n",
      " Matteo Treleani ¬¨ Crossing Borders Archives. The Circulation of Stock Shots in Audiovisual Media\n",
      "Michael Nicola Carboni ¬¨ The Structures of Visual Exchanges\n",
      "Mila Oiva ¬¨ Using Multidimensional Vector Embeddings to Study Temporal Dimensions of Historical Newsreel Data\n",
      " Tanya Clement ¬¨ AVAnnotate: Creating Scholarly Editions and Exhibits with IIIF and AV Archives\n",
      " Nabeel Siddiqui ¬¨ Bipartite Frame Networks in the Analysis of Film\n",
      " Th√©o Heugebaert ¬¨ Visualizing Rhythms Through Digital Annotations\n",
      " B√©r√©nice Serra & L√©na Frei ¬¨ Intuitive Access to Oral History Video (The Pellaton Experience)\n",
      " Diane Jakacki ¬¨ The Linked Editing Academic Framework (LEAF) in the Multimodal Annotation Ecosystem\n",
      " R√©gis Robineau ¬¨ Overview of the IIIF Initiative for Interoperability of Digital Objects on the Web \n",
      " Jean-Christophe Carius & Chlo√© Pochon ¬¨ From Source Annotation to Scientific Publishing\n",
      " Clarisse Bardiot & Jacob Hart ¬¨ IIIF', ' a Standard for Multimodal Corpora? The Building of SCENE\n",
      " Melvin Wevers ¬¨ A Multimodal Turn? Navigating AI Developments in Digital Humanities\n",
      " Delfina Sol Martinez Pandiana ¬¨ Coding the Encoder\n",
      " Marie-Claude Poulin ¬¨ VR & AR Prototypes for Multi-sensory [...] Forms of Documentation\n",
      " Lauren Tilton ¬¨ TV as Cultural Heritage: Exploring Multimodal Approaches\n",
      " Rime Touil ¬¨ Curating Born-Digital Archives at the National Library of France\n",
      " Luca Federico Cerra and Sean Takats ¬¨ Two Historians' Relationship with Sources in the Digital Age\n",
      " Julien Schuh ¬¨ AI Toolkits for the Social Sciences and Humanities: [...] PictorIA\n",
      " Susan Brown ¬¨ The Linked Infrastructure for Networked Cultural Scholarship (LINCS)\n",
      "Bunbuku\n",
      "{'id': 'http://127.0.0.1:5500/manifest_1.json', 'type': 'Manifest', 'label': {'en': ['Opening statements']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Opening statements'}, {'label': 'Speaker', 'value': 'Clarisse Bardiot & Jacob Hart (organizers)'}, {'label': 'Description', 'value': \"DAY 1 - Speaking order : ']\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=lJ3GbPuPC8Y'}, {'label': 'Tag', 'value': ''}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1442, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=lJ3GbPuPC8Y', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1442, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_2.json', 'type': 'Manifest', 'label': {'en': ['Keynote - Scott deLaHunta ¬¨ Software for Dancers']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Keynote - Scott deLaHunta ¬¨ Software for Dancers'}, {'label': 'Speaker', 'value': 'Scott deLaHunta'}, {'label': 'Description', 'value': \"DAY 1 - Piecemaker was a video annotation software used by The Forsythe Company in Frankfurt from 2007-2013 to aid the ensemble in recalling material they were working on in the studio in the context of choreographic creation. Most of the annotations were made live', ' with a static camera', ' while creative work was happening. These recordings were never intended to be made public. In 2010', ' the Motion Bank project took on the task of developing this software for wider public use in the dance community. Since then', ' different versions have been made and used for several projects. This development has been supported with research funding from various sources', ' and the software is now completely open source. Crucially', ' the focus has remained on making a digital (documentation) tool that is usable and useful for dance practitioners', ' both artists and educators. This focus will form the core of this talk', ' including insights into methods into language-use gained from the Motion Bank research. I will reflect on the nature of dance processes and knowledge to address some critical questions that come up in the context of developing usable and useful software for dancers. I will lightly trace a history of this from the multimedia 1990s to the current data-driven and AI preoccupied present', ' and speculate on what this might mean for the understanding and valuing of bodily practices.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=5JopAb3YFJE'}, {'label': 'Tag', 'value': \"choregraphy', ' dance', ' Motion Bank\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 3726, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=5JopAb3YFJE', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 3726, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_3.json', 'type': 'Manifest', 'label': {'en': [\"Olivier Aubert ¬¨ Advene', ' a Look Back on 20 Years of Video Annotation Instrumentation\"]}, 'context': None, 'metadata': [{'label': 'Title', 'value': \"Olivier Aubert ¬¨ Advene', ' a Look Back on 20 Years of Video Annotation Instrumentation\"}, {'label': 'Speaker', 'value': 'Olivier Aubert'}, {'label': 'Description', 'value': \"DAY 2 - Advene is a research project and a video annotation tool that started in 2002. It aims at enabling users to practice active reading on their audiovisual documents', ' originally focusing on movies. At that time', ' video on the web was basically not usable', ' except through proprietary plugins that prevented external control. We chose to consider DVDs', ' which were the main stable and legal source of video documents. Presently', ' Advene remains actively maintained and utilized', ' and has adapted to the technological and conceptual changes of the ecosystem', ' to be able for instance to annotate online videos using ontologies. It is still used in its original application of media studies', ' but has also been used in other fields such as sociology', ' ethology', ' arts‚Ä¶Positioned within the realm of Digital Humanities', ' Advene reflects the dichotomy inherent to such projects: digitization brings powerful tools and methods to humanities', ' but also a number of constraints', ' limitations and methodological changes that have to be taken into account. We would like to take a look back on this 20-year experience to provide some lessons learned about furnishing end-users with an effective video annotation tool', ' based on the experience of past and current projects.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=VZuv0QTLkDc'}, {'label': 'Tag', 'value': \"annotation', ' interoperability', ' COCoNotes\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2139, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=VZuv0QTLkDc', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2139, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_4.json', 'type': 'Manifest', 'label': {'en': ['Mark J. Williams ¬¨ Deep Screens and Evocative Surfaces']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Mark J. Williams ¬¨ Deep Screens and Evocative Surfaces'}, {'label': 'Speaker', 'value': 'Mark J. Williams'}, {'label': 'Description', 'value': 'DAY 2 - Deep Screens is a Mellon Foundation Public Knowledge Project that will rip moving image files from hundreds of select dvd\\'s and then use machine learning software to extract and analyze performance movements and expressions across this vast curated collection of U.S. film and television texts from 1895 to the 1970s. This movement and performance data will then be statistically analyzed\", \\' with derivatives and results made available in Dataverse through a partnership with the Dartmouth Library. To make the movement data more relatable\\', \\' motions and gestures will also be applied to animated avatars that can be viewed in virtual reality\\', \\' abstracted from the context of the original film or television text. The combination of quantitative analysis of the data itself and qualitative viewing of the abstracted movements will provide insight into how acting\\', \\' cinematography\\', \\' and technology have evolved across the span of moving image history.'}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=nXYbTjyDyvQ'}, {'label': 'Tag', 'value': \"movement analyze', ' movie', ' machine learning\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2011, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=nXYbTjyDyvQ', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2011, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_5.json', 'type': 'Manifest', 'label': {'en': ['Michael Rau & Peter Broadwell ¬¨ Machine Intelligence for Motion Exegesis (MIME)']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Michael Rau & Peter Broadwell ¬¨ Machine Intelligence for Motion Exegesis (MIME)'}, {'label': 'Speaker', 'value': ' Michael Rau & Peter Broadwell '}, {'label': 'Description', 'value': \"DAY 2 - MIME is a collaborative effort between faculty in the Department of Theater and Performance Studies at Stanford University and developers at the Stanford Libraries‚Äô Center for Interdisciplinary Digital Research. The project incorporates a suite of software tools for applying deep learning-based pose and gesture estimation to recorded theatrical performances', ' coupled with a database-backed web interface to facilitate close evaluation and refinement of data inputs and analytical outputs via interactive visualizations and built-in code notebooks. Previously unexplored', ' computationally oriented research inquiries in performance studies drive the collaboration; these include characterization of the range of choreographed poses within a performance', ' tracking the evolution of actors‚Äô embodiment of a role', ' and comparative thematic and stylistic analysis of performances.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=7ujK78287FE'}, {'label': 'Tag', 'value': \"theater', ' deep learning', ' gesture record\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2000, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=7ujK78287FE', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2000, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_6.json', 'type': 'Manifest', 'label': {'en': [' Matteo Treleani ¬¨ Crossing Borders Archives. The Circulation of Stock Shots in Audiovisual Media']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Matteo Treleani ¬¨ Crossing Borders Archives. The Circulation of Stock Shots in Audiovisual Media'}, {'label': 'Speaker', 'value': ' Matteo Treleani '}, {'label': 'Description', 'value': \" DAY 2 - The ANR CROBORA project aims to shed light on the repetitive and memorial dimension of stock shots in audiovisual media. In partnership with Ina', ' Rai Radiotelevisione Italiana and Mediaset', ' 35', '000 stock images linked to European integration were collected from twenty years of French and Italian television news', ' as well as a selection of web accounts. A visualization platform and analysis tools have been implemented to analyze this sample of mediatized visual memory. This talk will focus on the issues involved in collecting', ' structuring', ' annotating and visualizing a complex and heterogeneous corpus.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=xQCg6OE0mAQ'}, {'label': 'Tag', 'value': \"stockshot', ' medias', ' ANR CROBORA\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1736, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=xQCg6OE0mAQ', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1736, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_7.json', 'type': 'Manifest', 'label': {'en': ['Michael Nicola Carboni ¬¨ The Structures of Visual Exchanges']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Michael Nicola Carboni ¬¨ The Structures of Visual Exchanges'}, {'label': 'Speaker', 'value': ' Nicola Carboni '}, {'label': 'Description', 'value': \" DAY 2 - In the history of representation', ' the illustrated press has functioned as a significant driving force', ' curating', ' and disseminating ideas of visuality to artists and a wider audience. However', ' how can we even grasp the interaction and circulation of the visual at scale? How is it possible to analyse and comprehend image globalization? To address these questions', ' the Visual Contagions project has developed (i) a large corpus of digitized image data and (ii) methodologies to analyse image exchanges across the globe. Thanks to this groundwork', ' the project has conducted several large-scale analyses of visual transmissions. However', ' this computational study intertwines algorithms', ' information and data with a historical and conceptual complexity that makes computational investigations difficult to frame. Each of these analyses', ' in fact', ' lays its foundation on an ontological decision about the nature of circulation: what does circulation entail? How can we express it? What actual insights can we gain from it? The answers to these questions are fundamental to the creation', ' and function', ' of information systems able to support the historical analysis of cultural exchanges. The article explores the technological limitations and possibilities in conceptualizing', ' curating', ' and integrating historical data faced by the Visual Contagions project', ' focusing specifically on the documentation and analysis of visual exchanges. \"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=Yf2pM2DsB88'}, {'label': 'Tag', 'value': \"Visual Contagions', ' image globalisation', ' art history', ' visual exchanges\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1820, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=Yf2pM2DsB88', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1820, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_8.json', 'type': 'Manifest', 'label': {'en': ['Mila Oiva ¬¨ Using Multidimensional Vector Embeddings to Study Temporal Dimensions of Historical Newsreel Data']}, 'context': None, 'metadata': [{'label': 'Title', 'value': 'Mila Oiva ¬¨ Using Multidimensional Vector Embeddings to Study Temporal Dimensions of Historical Newsreel Data'}, {'label': 'Speaker', 'value': ' Mila Oiva '}, {'label': 'Description', 'value': \" DAY 2 - How to study the visual discourses', ' emerging from large-scale visual heritage data', ' in a way that allows the findings to rise from the data', ' instead of assigning the types of visual representations in advance? And how to grasp temporal changes in these visual discourses? This presentation showcases uses of the Collection Space Navigator (CSN) (Ohm et al.) to analyze central shot frames of historical newsreels to reveal continuities and changes in visual discourses of Soviet newsreels 1944-1992. We used a pre-trained ResNet50 model to encode the newsreel frames into 2048-dimensional feature vectors. After that we used the CSN tool to visualize the encoded images with two-dimensional UMAP projection. This approach allows visual exploration of image collections', ' which in our case study can be used to reveal also temporal visual patterns.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=TCz7--75hTs'}, {'label': 'Tag', 'value': \"historical newsreel', ' Collection Space Navigator(CSN)', ' visual discourses\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1565, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=TCz7--75hTs', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1565, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_9.json', 'type': 'Manifest', 'label': {'en': [' Tanya Clement ¬¨ AVAnnotate: Creating Scholarly Editions and Exhibits with IIIF and AV Archives']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Tanya Clement ¬¨ AVAnnotate: Creating Scholarly Editions and Exhibits with IIIF and AV Archives'}, {'label': 'Speaker', 'value': ' Tanya Clement '}, {'label': 'Description', 'value': \" DAY 2 - Increased concern over media degradation and obsolescence combined with the decreasing cost of digital storage has led libraries', ' archives', ' and museums (LAMs) to digitize audiovisual (AV) materials for improved access and long-term preservation. Yet', ' improving preservation and access must go beyond digitization. While they are sometimes the only record of an event or an aural', ' visual', ' or performance tradition', ' AV digital artifacts remain underused and understudied. IIIF (International Image Interoperability Framework) is one standardized solution that LAMs have adopted to give users the ability to perform basic humanities methods including annotating', ' comparing', ' discovering', ' illustrating', ' referring', ' representing', ' and sampling images. In 2020', ' IIIF extended the IIIF API to accommodate rendering AV in a web browser. In response to the need for a workflow that supports IIIF manifest creation', ' collaborative editing', ' flexible modes of presentation', ' and permissions control', ' we developed the AVAnnotate project. AVAnnotate facilitates sharing annotations on AV archives through a sustainable workflow that leverages IIIF and simplifies the production of online AV projects that provide commentary and context around under-used and culturally sensitive AV collections. Existing projects include curricula for recorded interviews with jailed student protestors during the Civil Rights movement', ' a bilingual edition of Radio Venceremos programs', ' a documentary of events at the Furious Flower Poetry Center', ' as well as oral histories from the Syilx Okanagan Peoples. The AVAnnotate project builds on IIIF to address gaps in increasing engagement with archival AV and providing a solution for standardized annotation collaboration and presentation.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=vOZwsiOUg3g'}, {'label': 'Tag', 'value': \"media preservation', ' IIIF', ' AVAnnotate', ' digitize audiovisual materials\"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2000, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=vOZwsiOUg3g', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2000, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_10.json', 'type': 'Manifest', 'label': {'en': [' Nabeel Siddiqui ¬¨ Bipartite Frame Networks in the Analysis of Film']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Nabeel Siddiqui ¬¨ Bipartite Frame Networks in the Analysis of Film'}, {'label': 'Speaker', 'value': '  Nabeel Siddiqui '}, {'label': 'Description', 'value': \" DAY 2 - This paper overviews a novel methodology that enhances traditional count-based analysis by leveraging', ' what I call', ' bipartite frame networks. Bipartite frame networks consist of two types of nodes. The first node type represents the frames of a film while the second refers to the measurable elements within them (e.g.', ' characters', ' objects). These nodes are then linked through edges that reflect their cooccurrence within a frame. By applying techniques from network science', ' bipartite frame networks make it possible for scholars to identify significant frame-to-element relationships', ' revealing patterns of composition and narrative structure that are not easily discernible through traditional count-based methods.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=JmJfRpeL5fk'}, {'label': 'Tag', 'value': \" Google Vision API', ' \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 919, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=JmJfRpeL5fk', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 919, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_11.json', 'type': 'Manifest', 'label': {'en': [' Th√©o Heugebaert ¬¨ Visualizing Rhythms Through Digital Annotations']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Th√©o Heugebaert ¬¨ Visualizing Rhythms Through Digital Annotations'}, {'label': 'Speaker', 'value': ' Th√©o Heugebaert '}, {'label': 'Description', 'value': \" DAY 2 - The rhythm of a performance', ' as an aesthetic and temporal sensation', ' although easily perceptible at first glance', ' becomes', ' upon closer examination', ' a complex object to apprehend : despite the striking impressions it may leave', ' it does not leave traces other than those in memory. While audio or video recordings allow us to access a reproduction of movements', ' our interest in rhythm lies in what moves within the movement. Moreover', ' as we seek to understand the evolution of rhythms during the creative process', ' our focus shifts to the mutations of what moves within the movement. With the help of audio and video recordings annotations', ' we can precisely attempt to overcome these challenges by detecting new traces and indicative clues revealing the nature of rhythms and their mutations during the creative process. Here', ' we will present the method that led us to deduce two indicators from the concept of rhythm', ' which are exploitable through the annotation of audio and video recordings and allow us to visualize and analyze the rhythms and their mutations during the creative process : speaking rate and a typology of rhythms performed by the actors.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=MIeu0M0ejjs'}, {'label': 'Tag', 'value': \" Dance', ' Rythme visualisation', ' Motion Bank \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 904, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=MIeu0M0ejjs', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 904, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_12.json', 'type': 'Manifest', 'label': {'en': [' B√©r√©nice Serra & L√©na Frei ¬¨ Intuitive Access to Oral History Video (The Pellaton Experience)']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' B√©r√©nice Serra & L√©na Frei ¬¨ Intuitive Access to Oral History Video (The Pellaton Experience)'}, {'label': 'Speaker', 'value': ' B√©r√©nice Serra & L√©na Frei '}, {'label': 'Description', 'value': ' DAY 2 - The Pellaton Experience\\', \\' a specialized web portal for dance research\\', \" was developed by the Institute Digital Communication Environments (IDCE) at HGK Basel FHNW in collaboration with the SAPA Foundation (Swiss Archive of Performing Arts). The SAPA Foundation\\'s archive houses interviews\", \\' dance notations\\', \\' video recordings\\', \\' and reviews\\', \\' offering a comprehensive view of the Swiss dance scene. Recent emphasis on the \"oral history\" research method resulted in a substantial collection of audiovisual data\\', \\' posing the challenge of making this unique content accessible to diverse audiences\\', \\' leading to the creation of the Pellaton Experience project. The lecture will explore how the research project strategically presents archival materials from oral history interview series\\', \\' aiming for a comprehensive understanding of the discussed topics. This effort was made possible through collaboration with an interdisciplinary team\\', \\' including experts in video/media\\', \\' art history\\', \\' and IT (SAPA)\\', \\' as well as professionals in graphic design\\', \\' project management\\', \\' game design\\', \\' and architecture (HGK Basel FHNW). Key research questions focus on user interface and user experience design\\', \\' aiming to optimize scenarios like \"expert search\" and \"uncoordinated browsing\" to enhance the overall choreographic experience. The project strives to provide innovative solutions to improve accessibility and deepen the understanding of the rich history within the SAPA Foundation\\\\\\'s archives. Consequently\\', \\' we will delve into specific aspects of this interface while also establishing broader connections with themes such as digital archives\\', \\' dance documentation\\', \\' oral history\\', \\' gesture in dance\\', \\' and design.'}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=r5JMj_xr_3c'}, {'label': 'Tag', 'value': \" Datavis', ' UX \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 852, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=r5JMj_xr_3c', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 852, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_13.json', 'type': 'Manifest', 'label': {'en': [' Diane Jakacki ¬¨ The Linked Editing Academic Framework (LEAF) in the Multimodal Annotation Ecosystem']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Diane Jakacki ¬¨ The Linked Editing Academic Framework (LEAF) in the Multimodal Annotation Ecosystem'}, {'label': 'Speaker', 'value': ' Diane Jakacki '}, {'label': 'Description', 'value': \" DAY 2 - The Linked Editing Academic Framework (LEAF) is a virtual research environment', ' a platform and suite of tools designed to support researchers working collaboratively in cultural heritage spaces', ' enabling them to undertake sophisticated editorial work in multiple media formats. Built with the Islandora repository framework', ' LEAF is based on linked data principles and interlinked with the larger LOD ecosystem', ' not only through its use of PIDs (Persistent Identifiers) but through a sophisticated toolset that allows novice as well as expert users to annotate cultural heritage materials at both meta- and granular-levels. The platform allows scholars to focus on their subject of study rather than to learn how to code', ' enabling researchers without extensive technical expertise to annotate content as part of their scholarly workflows. LEAF mobilizes some tools by directly integrating them into the platform; others are supported indirectly by either providing compatible outputs or supporting/retooling their outputs; and some core components are also modular so they can serve as stand-alone tools or be integrated in other systems.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=c24HgcNoRTY'}, {'label': 'Tag', 'value': \" Digital edition', ' Plateform \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1129, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=c24HgcNoRTY', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1129, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_14.json', 'type': 'Manifest', 'label': {'en': [' R√©gis Robineau ¬¨ Overview of the IIIF Initiative for Interoperability of Digital Objects on the Web ']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' R√©gis Robineau ¬¨ Overview of the IIIF Initiative for Interoperability of Digital Objects on the Web '}, {'label': 'Speaker', 'value': ' R√©gis Robineau '}, {'label': 'Description', 'value': \" DAY 2 - This talk will give an overview of the IIIF initiative', ' its history', ' challenges and recent developments within the consortium. It will then outline the IIIF standards (APIs) and the resulting ecosystem of applications and tools. Finally', ' it will also take a general look at the adoption and use of IIIF in France.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=oN2WgNMlU7M'}, {'label': 'Tag', 'value': ' IIIF '}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1685, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=oN2WgNMlU7M', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1685, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_15.json', 'type': 'Manifest', 'label': {'en': [' Jean-Christophe Carius & Chlo√© Pochon ¬¨ From Source Annotation to Scientific Publishing']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Jean-Christophe Carius & Chlo√© Pochon ¬¨ From Source Annotation to Scientific Publishing'}, {'label': 'Speaker', 'value': ' Jean-Christophe Carius & Chlo√© Pochon '}, {'label': 'Description', 'value': \" DAY 2 - Using examples drawn from the development of the PENSE platform', ' we will present a synthesis of lessons learned in our approach to the encoding of historical sources in art history', ' and more specifically to the enrichment of textual and visual historical sources. We will show how data annotation can be seen as a key point in the process of enriching these sources and we will demonstrate some of the workflows and interfaces we have developed for this purpose. Finally', ' we will also address the question of how this mode of research through annotation can be incorporated into the flow of a scientific article and we will present the principles of a forthcoming project produced by INHA', ' PerVisum', ' that aims to develop a scientific publishing format based on the annotation of visual sources.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=-tEA_vRL2rU'}, {'label': 'Tag', 'value': \" PENSE', ' art history', ' annotation \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1666, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=-tEA_vRL2rU', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1666, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_16.json', 'type': 'Manifest', 'label': {'en': [\" Clarisse Bardiot & Jacob Hart ¬¨ IIIF', ' a Standard for Multimodal Corpora? The Building of SCENE\"]}, 'context': None, 'metadata': [{'label': 'Title', 'value': \" Clarisse Bardiot & Jacob Hart ¬¨ IIIF', ' a Standard for Multimodal Corpora? The Building of SCENE\"}, {'label': 'Speaker', 'value': ' Clarisse Bardiot & Jacob Hart '}, {'label': 'Description', 'value': ' DAY 2 - Following literature genetic criticism\\', \\' performing arts studies developed since the 1990‚Äôs performance genetic analysis\\', \\' shifting the research focus from the work to its creative process. In this new research field\\', \\' scholars long directed their effort to participant observation of rehearsals. Digital traces\\', \\' often ignored in actual research on creative processes\\', \" offer new opportunities: produced by every member of the team they allow us to consider the whole creation process from the very first ideas to the premiere. The usual practices of digital humanities are to separate documents by file type and to work in \\'silos\\' (text\", \\' image...). Such processing prevents us from obtaining an overall view of the collected traces and from examining many phenomena such as the evolution of an idea through different traces\\', \\' from an image to a text\\', \\' from a text to a video recording. Another challenge of distant reading and datavisualisation is the loss of the overall view of the trace and the context from which the data was extracted. In order to answer these two main issues\\', \\' we present SCENE\\', \\' an open source web app. SCENE‚Äôspoint of departure is IIIF (International Image Interoperability Framework). Initially conceived of as a set of standards to allow for interoperable sharing\\', \\' referencing and annotation of digital images\\', \\' we use it as a framework at the base of an environment for multimodal document network analysis. This project follows a practice-driven approach to development based on case studies and workshops\\', \\' notably in the context of Clarisse Bardiot‚Äôs ERC-funded STAGE project.'}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=E-BOXpORxIc'}, {'label': 'Tag', 'value': \" IIIF', ' Scene', ' Memorikall', ' Mirador', ' Performance genetic analysis \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1882, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=E-BOXpORxIc', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1882, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_17.json', 'type': 'Manifest', 'label': {'en': [' Melvin Wevers ¬¨ A Multimodal Turn? Navigating AI Developments in Digital Humanities']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Melvin Wevers ¬¨ A Multimodal Turn? Navigating AI Developments in Digital Humanities'}, {'label': 'Speaker', 'value': ' Melvin Wevers '}, {'label': 'Description', 'value': \" DAY 2 - In the ever-evolving landscape of Digital Humanities (DH)', ' research methodologies predominantly centered on textual data. However', ' the advent of deep learning revolutionized this scope', ' enabling the automated analysis and labeling of visual materials. Despite their capabilities', ' these early methods demanded extensive training datasets. The landscape saw another transformation with the rise of multimodal deep learning architectures', ' such as the Contrastive Language Image Pre-training (CLIP). Such innovations brought about a convergence of GPT-inspired interfaces for visual analysis', ' broadening the ambit of multimodal research. These technological leaps have now positioned humanists on the cusp of computational visual analysis.']\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=j7iBhiODQmY'}, {'label': 'Tag', 'value': \" Digital History', ' Multimodal Large Langage Model (MMLLM) \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 4114, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=j7iBhiODQmY', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 4114, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_18.json', 'type': 'Manifest', 'label': {'en': [' Delfina Sol Martinez Pandiana ¬¨ Coding the Encoder']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Delfina Sol Martinez Pandiana ¬¨ Coding the Encoder'}, {'label': 'Speaker', 'value': ' Delfina Sol Martinez Pandiana '}, {'label': 'Description', 'value': \" DAY 3 - The talk explores the assignment of subjective high-level annotations to visual data in computer vision pipelines. It addresses how this annotated data is utilized to train AI models', ' highlighting the common lack of situational context', ' and the biases introduced. The talk describes the SituAnnotate methodology', ' which extends the data annotation process to include rich contextual information', ' such as sources', ' and financial/temporal/geographical contexts. This approach not only provides a comprehensive understanding of the situational grounding of annotations but also offers insights to mitigate biases', ' enhance model understanding', ' and empower AI practitioners in curating datasets aligned with specific criteria. The talk serves as a bridge between high-level semantic annotations and the imperative to reimagine annotation for cultural data', ' emphasizing the crucial role of situating context and socio-cultural factors in responsible AI system development.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=osy_twtjkMs'}, {'label': 'Tag', 'value': \" AI training', ' SituAnnotate methodology', ' Mecanical Turk workers \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1814, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=osy_twtjkMs', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1814, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_19.json', 'type': 'Manifest', 'label': {'en': [' Marie-Claude Poulin ¬¨ VR & AR Prototypes for Multi-sensory [...] Forms of Documentation']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Marie-Claude Poulin ¬¨ VR & AR Prototypes for Multi-sensory [...] Forms of Documentation'}, {'label': 'Speaker', 'value': ' Marie-Claude Poulin '}, {'label': 'Description', 'value': ' DAY 3 - The presentation introduces the development of virtual and augmented reality prototypes designated as a \"Virtual Meta-Set\" for three existing digital art installation/performance works and their processual artifacts. These are designed to simulate and reconstitute the artworks and their genesis history in a virtual environment that allows travel between them and their documentary and annotative material. The goal is to investigate the constitution of a 3D archival user experience in which the metadata of each creation process are accessible and can be cross-referenced at any time.The database contains ‚Äúclassical‚Äù and atypical documentary components such as lines of code and user data\\', \\' distributed and staged in the same multi-layered virtual landscape. A portable controller allows users to access hyperlinks\\', \\' manipulate virtual assets\\', \\' and reorganize the space. Through their actions\\', \\' they explore the environment\\', \\' and a tracking of their movements\\', \\' combined with their manual and verbal commands\\', \\' turns the virtual space in a walkable\\', \\' haptic experience.Bringing distinct artworks to converge in this ‚ÄúVirtual Meta-Set‚Äù is not simply a technical feat\\', \\' it is an artistic mission which\\', \\' through simulation and immersive reconstitution\\', \\' generates a new form of re-enactment. The challenge is also to test whether this type of epistemological-artistic environment\\', \\' in which the immersion factor is an integral part\\', \\' can lead to a new kind of meta-reflection on creative processes.'}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=wImmW-Tv6SE'}, {'label': 'Tag', 'value': \" Virtual reality', ' Augmented reality', ' digital art \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1603, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=wImmW-Tv6SE', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1603, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_20.json', 'type': 'Manifest', 'label': {'en': [' Lauren Tilton ¬¨ TV as Cultural Heritage: Exploring Multimodal Approaches']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Lauren Tilton ¬¨ TV as Cultural Heritage: Exploring Multimodal Approaches'}, {'label': 'Speaker', 'value': ' Lauren Tilton '}, {'label': 'Description', 'value': \" DDAY 3 - The talk will explore text', ' image', ' and sound analysis of TV sitcoms. As syndicated TV becomes understood as a form of cultural heritage', ' institutions and researchers are looking more closely at how to access and study these popular culture forms through computational methods. We will look at some initial multimodal explorations and discuss future possibilities.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=BswZ9kt9uB0'}, {'label': 'Tag', 'value': \" Media studies', ' Object & personn detection', ' Sitcom \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1869, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=BswZ9kt9uB0', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1869, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_21.json', 'type': 'Manifest', 'label': {'en': [' Rime Touil ¬¨ Curating Born-Digital Archives at the National Library of France']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Rime Touil ¬¨ Curating Born-Digital Archives at the National Library of France'}, {'label': 'Speaker', 'value': ' Rime Touil '}, {'label': 'Description', 'value': ' DAY 3 - In 2018\\', \\' the Performing Arts Department of the National Library of France received an exceptional donation from director Amos Gita√Ø comprising his entire physical and digital archives surrounding his film Rabin\\', \\' The Last Day (2015). Representing almost 19 TB of data including text files\\', \\' photographs\\', \\' sound files\\', \\' web pages and most of all\\', \\' videos\\', \" covering all stages of the film\\'s creation from the script writing to its final editing\", \\' this collection poses unprecedented scientific and technical challenges. The massive number of documents and the wide variety of formats they represent\\', \\' as well as the skills required to handle them\\', \\' raised the question of the processes to use to identify these archives\\', \\' to make them available to the public and\\', \\' ultimately\\', \\' to preserve them on the long term\\', \\' bringing into light the tension that can exist between preservation requirements and the need for easily accessible archives. To accommodate this kind of complex digital collection\\', \\' the BnF reflected on new tools specifically designed for born-digital archives\\', \\' one of them being an application dedicated to the curating of born-digital archives\\', \\' called TriNum. Conceived to enable the classifying\\', \\' the annotation and the creation of preservation units\\', \\' as well as to manage and trace the transformations carried out on these documents prior to their preservation\\', \\' this interface keeps evolving to meet the challenges raised by the numerous born-digital collections received by the BnF these past few years. This lecture intends to present the state of the art on digital curating at the BnF while displaying the methodology\\', \\' solutions and strategies implemented during the processing of the Amos Gitai collection.'}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=wwFcsJpQK5I'}, {'label': 'Tag', 'value': \" Archive', ' Performing Arts', ' BnF \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2552, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=wwFcsJpQK5I', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2552, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_22.json', 'type': 'Manifest', 'label': {'en': [\" Luca Federico Cerra and Sean Takats ¬¨ Two Historians' Relationship with Sources in the Digital Age\"]}, 'context': None, 'metadata': [{'label': 'Title', 'value': \" Luca Federico Cerra and Sean Takats ¬¨ Two Historians' Relationship with Sources in the Digital Age\"}, {'label': 'Speaker', 'value': ' Luca Federico Cerra and Sean Takats '}, {'label': 'Description', 'value': \" DThis paper examines the annotation practices behind DHARPA (the Digital History Advanced Research Accelerator project) and its innovative data orchestration tool', ' kiara. By focusing on the importance of annotation across various stages of research', ' kiara aims to enhance transparency and traceability in humanities research. Kiara‚Äôs design draws on the wide range of research experiences of the project‚Äôs team members and its collaborators. Here we explore two specific research problems experienced by this paper‚Äôs authors: Takats‚Äôs research on colonial medical practitioners involves the identification of geographic patterns of expert knowledge production and circulation; Cerra seeks to highlight the interactions between craftsmen and administrators in Revolutionary France', ' thus', ' uncovering a network of exchanges involving family', ' neighborhood', ' or professional ties. In both cases', ' our research depends not just on the creation', ' analysis', ' and visualization of data drawn from archival sources and finding aids', ' but also on the careful supervision and documentation of the decisions made along the way. Kiara aims to assist this process through a combination of automated and intentional annotation. Our paper considers the complexity of developing software which promotes critical reflection rather than simply racing to a solution.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=wenREKPYzCQ'}, {'label': 'Tag', 'value': \" History', ' Kiara', ' Annotation \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 2015, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=wenREKPYzCQ', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 2015, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_23.json', 'type': 'Manifest', 'label': {'en': [' Julien Schuh ¬¨ AI Toolkits for the Social Sciences and Humanities: [...] PictorIA']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Julien Schuh ¬¨ AI Toolkits for the Social Sciences and Humanities: [...] PictorIA'}, {'label': 'Speaker', 'value': ' Julien Schuh '}, {'label': 'Description', 'value': \" DAY 3 - The exploration of vast digital archives', ' now increasingly accessible due to the digitization policies of numerous heritage institutions', ' poses a unique challenge. This communication offers an insight into a series of projects deploying AI toolkits to transform the management', ' analysis', ' and valorization of cultural heritage. Bridging the gap between historians', ' linguists', ' engineers', ' and conservators', ' these initiatives offer methods for complex image segmentation', ' pattern recognition', ' and automated text analysis. These projects utilize accessible data via APIs from various institutions for model training and fine-tuning', ' focusing on creating specialized corpora and refining AI methodologies. The collective outcomes of these projects have led to the inception of a national consortium project focused on exploring extensive image corpora within heritage collections and research archives.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=IXNzptrvYVA'}, {'label': 'Tag', 'value': ' IA '}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1879, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=IXNzptrvYVA', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1879, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n",
      "{'id': 'http://127.0.0.1:5500/manifest_24.json', 'type': 'Manifest', 'label': {'en': [' Susan Brown ¬¨ The Linked Infrastructure for Networked Cultural Scholarship (LINCS)']}, 'context': None, 'metadata': [{'label': 'Title', 'value': ' Susan Brown ¬¨ The Linked Infrastructure for Networked Cultural Scholarship (LINCS)'}, {'label': 'Speaker', 'value': ' Susan Brown '}, {'label': 'Description', 'value': \" DAY 3 - Culture operates increasingly as data', ' as does scholarship. While GLAM institutions create highly standardized and generalized metadata for their collections', ' scholars embed deep knowledge of those items within collections through their research. Web annotations', ' via the Web Annotation Data Model (Sanderson et al.', ' 2017)', ' are one way to bring together the data about these items and point to the expert contextualization', ' scholarly debates', ' and situated knowledge created about them. Linked Infrastructure for Networked Cultural Scholarship (LINCS) is an infrastructure to allow scholars to transform or create linked open data (LOD) about cultural materials. LINCS is working with GLAM institutions in Canada to build relationships between people; between data; between people and data', ' cultural organizations', ' and machines. The LINCS team chose the CIDOC-CRM and the WADM as complementary ontologies (Application Profile). CIDOC is increasingly used by cultural heritage organizations', ' but the WADM offers a flexible W3C standard for linking data to various resources on the web', ' including and beyond projects related to LINCS (Canning et al.', ' 2022). In this respect', ' LINCS is aligned with Europeana', ' which has adopted elements of both CIDOC-CRM and the WADM in their Annotations API (https://pro.europeana.eu/page/annotat....) This paper will reflect on the implications', ' benefits', ' and challenges that LINCS has encountered to date from creating and publishing data that combines these two ontological structures.\"}, {'label': 'Place', 'value': 'University Rennes 2'}, {'label': 'URL', 'value': 'https://www.youtube.com/watch?v=DyJ_3O75Csc'}, {'label': 'Tag', 'value': \" LINCS', ' Web annotation', ' metadata \"}], 'summary': None, 'requiredStatement': None, 'rendering': None, 'service': None, 'services': None, 'viewingDirection': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'rights': None, 'start': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas1', 'type': 'Canvas', 'label': None, 'height': 113, 'width': 200, 'duration': 1762, 'metadata': None, 'summary': None, 'requiredStatement': None, 'rendering': None, 'rights': None, 'navDate': None, 'navPlace': None, 'provider': None, 'seeAlso': None, 'service': None, 'placeholderCanvas': None, 'accompanyingCanvas': None, 'thumbnail': None, 'homepage': None, 'behavior': None, 'partOf': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page', 'type': 'AnnotationPage', 'label': None, 'context': None, 'rendering': None, 'service': None, 'thumbnail': None, 'items': [{'id': 'http://127.0.0.1:5500/canvas/page/annotation', 'type': 'Annotation', 'label': None, 'service': None, 'rendering': None, 'thumbnail': None, 'motivation': 'painting', 'body': {'id': 'https://www.youtube.com/watch?v=DyJ_3O75Csc', 'type': 'Video', 'height': 113, 'width': 200, 'duration': 1762, 'language': None, 'rendering': None, 'service': None, 'format': 'video/MPG', 'label': None, 'thumbnail': None, 'annotations': None}, 'target': 'http://127.0.0.1:5500/canvas1'}]}], 'annotations': None}], 'structures': None, 'annotations': None}\n",
      "_________________________________\n"
     ]
    }
   ],
   "source": [
    "md_to_manifest(MARKDOWN_PATH, MANIFEST_PATH, ARVEST_MAIL, ARVEST_PASSWORD)\n",
    "\n",
    "metadata_update(MARKDOWN_PATH, MANIFEST_PATH, ARVEST_MAIL, ARVEST_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
